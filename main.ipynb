{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxxQRovhQxz6",
        "outputId": "36da5e42-e4ac-49d2-9a26-5100221d4a65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Step 1: Installing, Importing, and Connecting to Drive ---\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Libraries are ready.\n",
            "\n",
            "Connecting to Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive connected.\n",
            "\n",
            "--- Configuring System Paths and Parameters ---\n",
            "Configuration complete. Ready for Step 2.\n"
          ]
        }
      ],
      "source": [
        "#-----Advanced Face Recognition System-----\n",
        "#Gadi Yohanan\n",
        "\n",
        "# ----------------- Installations and Imports -----------------\n",
        "print(\"--- Step 1: Installing, Importing, and Connecting to Drive ---\")\n",
        "!pip install insightface==0.7.3 onnx onnxruntime-gpu pandas ipywidgets matplotlib -q\n",
        "import os, pickle\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd, cv2, numpy as np, insightface\n",
        "from insightface.app import FaceAnalysis\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "print(\"Libraries are ready.\")\n",
        "\n",
        "# ----------------- Connect to Google Drive -----------------\n",
        "print(\"\\nConnecting to Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive connected.\")\n",
        "\n",
        "# ==============================================================================\n",
        "#                           System Configuration\n",
        "# ==============================================================================\n",
        "print(\"\\n--- Configuring System Paths and Parameters ---\")\n",
        "\n",
        "# 1. Full path to the folder in Google Drive\n",
        "DB_SOURCE_IMAGES_PATH = \"/content/drive/MyDrive/LFW\"\n",
        "\n",
        "# 2. Name and path of the file where the vector database will be saved\n",
        "VECTORS_DB_PATH = os.path.join(DB_SOURCE_IMAGES_PATH, \"insightface_database.pkl\")\n",
        "\n",
        "# 3. Similarity Threshold (Higher score = more similar)\n",
        "RECOGNITION_THRESHOLD = 0.5  # Good starting value, can be calibrated\n",
        "\n",
        "print(\"Configuration complete. Ready for Step 2.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_J0rGsDQzAa",
        "outputId": "cd537491-7ed2-493d-cb25-bbd7b664a569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Step 2: Building Vector Database (will run only if needed) ---\n",
            "Database file already exists at '/content/drive/MyDrive/LFW/insightface_database.pkl'.\n",
            "Loaded existing database with 2366 vectors.\n",
            "Skipping creation. You can proceed to Step 3.\n",
            "\n",
            "--- Vector Database is ready. Proceed to Step 3. ---\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "#           Step 2: Building Vector Database\n",
        "# ==============================================================================\n",
        "print(\"--- Step 2: Building Vector Database (will run only if needed) ---\")\n",
        "\n",
        "# --- Check if database already exists ---\n",
        "if os.path.exists(VECTORS_DB_PATH):\n",
        "    print(f\"Database file already exists at '{VECTORS_DB_PATH}'.\")\n",
        "    db_df_check = pd.read_pickle(VECTORS_DB_PATH)\n",
        "    print(f\"Loaded existing database with {len(db_df_check)} vectors.\")\n",
        "    print(\"Skipping creation. You can proceed to Step 3.\")\n",
        "else:\n",
        "    # --- Load the model ---\n",
        "    print(\"Database not found. Loading InsightFace model (buffalo_l)...\")\n",
        "    app = FaceAnalysis(name='buffalo_l', providers=['CUDAExecutionProvider'])\n",
        "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
        "    print(\"Model loaded.\")\n",
        "\n",
        "    # --- Create the database ---\n",
        "    print(\"Creating new vector database...\")\n",
        "    all_faces_data = []\n",
        "    celebrity_folders = [d for d in os.listdir(DB_SOURCE_IMAGES_PATH) if os.path.isdir(os.path.join(DB_SOURCE_IMAGES_PATH, d))]\n",
        "\n",
        "    for person_name in tqdm(celebrity_folders, desc=\"Processing Celebrities\"):\n",
        "        person_folder_path = os.path.join(DB_SOURCE_IMAGES_PATH, person_name)\n",
        "        for image_file in os.listdir(person_folder_path):\n",
        "            image_path = os.path.join(person_folder_path, image_file)\n",
        "            try:\n",
        "                img = cv2.imread(image_path)\n",
        "                faces = app.get(img)\n",
        "                if faces:\n",
        "                    embedding = faces[0].normed_embedding\n",
        "                    face_data = {\"name\": person_name, \"embedding\": embedding, \"image_path\": image_path}\n",
        "                    all_faces_data.append(face_data)\n",
        "            except Exception as e:\n",
        "                print(f\"\\nCould not process {image_path}: {e}\")\n",
        "\n",
        "    if all_faces_data:\n",
        "        db_df = pd.DataFrame(all_faces_data)\n",
        "        print(f\"\\nProcessed a total of {len(db_df)} images.\")\n",
        "        print(f\"Saving database to '{VECTORS_DB_PATH}'...\")\n",
        "        db_df.to_pickle(VECTORS_DB_PATH)\n",
        "        print(\"Database created successfully!\")\n",
        "    else:\n",
        "        print(\"No faces were processed.\")\n",
        "\n",
        "print(\"\\n--- Vector Database is ready. Proceed to Step 3. ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b8_jOrPOQ0Y6",
        "outputId": "0b214321-9160-4a79-a26f-8755acbca285"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "#           Final Application\n",
        "# ==============================================================================\n",
        "print(\"--- Final Application: Face Recognition with Core Attributes ---\")\n",
        "\n",
        "# --- 0. Installations and Imports (if needed) ---\n",
        "!pip install gradio -q\n",
        "import gradio as gr, os, cv2, numpy as np, pandas as pd\n",
        "from PIL import Image\n",
        "from insightface.app import FaceAnalysis\n",
        "\n",
        "# --- 1. Load Resources ---\n",
        "print(\"Loading resources for the application...\")\n",
        "\n",
        "if 'app' not in locals() or 'genderage' not in app.models: # Check if the correct model is loaded\n",
        "    print(\"Loading InsightFace model with gender/age estimation...\")\n",
        "    app = FaceAnalysis(allowed_modules=['detection', 'recognition', 'genderage'])\n",
        "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
        "    print(\"Model loaded.\")\n",
        "\n",
        "try:\n",
        "    VECTORS_DB_PATH = \"/content/drive/MyDrive/LFW/insightface_database.pkl\"\n",
        "    RECOGNITION_THRESHOLD = 0.4\n",
        "\n",
        "    db_df = pd.read_pickle(VECTORS_DB_PATH)\n",
        "    all_db_embeddings = np.array(db_df['embedding'].tolist())\n",
        "    print(f\"Successfully loaded vector database.\")\n",
        "except Exception as e:\n",
        "    db_df = None\n",
        "    print(f\"FATAL ERROR: Could not load vector DB. Please run previous steps first. Error: {e}\")\n",
        "\n",
        "# --- 2. Main Recognition Function ---\n",
        "def find_identity_insightface(new_embedding, db_df, all_db_embeddings, threshold):\n",
        "    if db_df is None or all_db_embeddings is None:\n",
        "        return \"Error\", 0.0\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarities = np.dot(all_db_embeddings, new_embedding)\n",
        "    best_match_index = np.argmax(similarities)\n",
        "    best_match_score = similarities[best_match_index]\n",
        "\n",
        "    if best_match_score < threshold:\n",
        "        return \"Unknown\", best_match_score\n",
        "\n",
        "    best_match_name = db_df.iloc[best_match_index]['name']\n",
        "    return best_match_name, best_match_score\n",
        "\n",
        "# --- 3. Wrapper function for Gradio ---\n",
        "def recognize_face_with_all_features(uploaded_image):\n",
        "    if uploaded_image is None or db_df is None:\n",
        "        return None, \"Please upload an image.\", None\n",
        "\n",
        "    img_rgb = uploaded_image.copy()\n",
        "    img_bgr = cv2.cvtColor(uploaded_image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    faces = app.get(img_bgr)\n",
        "\n",
        "    if not faces:\n",
        "        return None, \"No face found in the image.\", None\n",
        "\n",
        "    face = faces[0]\n",
        "    new_embedding = face.normed_embedding\n",
        "\n",
        "    # --- Extract Face Attributes ---\n",
        "    detected_gender = \"Male\" if face.sex == 'M' else \"Female\"\n",
        "    detected_age = face.age\n",
        "    if detected_age < 0:\n",
        "        detected_age = \"Unknown\"\n",
        "    elif detected_age > 100:\n",
        "        detected_age = \"Over 100\"\n",
        "    else:\n",
        "        detected_age = int(detected_age)\n",
        "\n",
        "    # --- Find Identity ---\n",
        "\n",
        "    name, score = find_identity_insightface(new_embedding, db_df, all_db_embeddings, RECOGNITION_THRESHOLD)\n",
        "\n",
        "    # --- Prepare Output ---\n",
        "    result_text = \"\"\n",
        "    gallery_images = None\n",
        "\n",
        "    if name not in [\"Unknown\", \"Error\"]:\n",
        "        display_name = name.replace('_', ' ').title()\n",
        "        result_text = f\"\"\"--- Recognition Details ---\\n**Identity:** {display_name}\\n**Similarity Score:** {score:.4f}\\n\\n--- Image Attributes ---\\n**Estimated Gender:** {detected_gender}\\n**Estimated Age:** ~{detected_age}\"\"\"\n",
        "\n",
        "        person_images_df = db_df[db_df['name'] == name]\n",
        "        gallery_images = person_images_df['image_path'].tolist()\n",
        "    else:\n",
        "        result_text = f\"\"\"--- Recognition Details ---\\n**Identity:** {name}\\n**Best Match Score:** {score:.4f}\\n\\n--- Image Attributes ---\\n**Estimated Gender:** {detected_gender}\\n**Estimated Age:** ~{detected_age}\"\"\"\n",
        "\n",
        "    # Draw keypoints on the image\n",
        "    keypoints = face.kps.astype(int)\n",
        "    for k_x, k_y in keypoints:\n",
        "        cv2.circle(img_rgb, (k_x, k_y), 3, (0, 255, 0), -1)\n",
        "\n",
        "    return img_rgb, gallery_images, result_text\n",
        "\n",
        "# --- 4. Build and Launch Gradio Interface ---\n",
        "print(\"\\n--- Launching Final Gradio Interface ---\")\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as iface:\n",
        "    gr.Markdown(\"# 🤖 Advanced Face Analysis System\")\n",
        "    gr.Markdown(\"Upload an image to identify a person, see their estimated attributes, view their photo gallery, and see the detected facial landmarks.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            input_image = gr.Image(type=\"numpy\", label=\"Upload Your Image Here\")\n",
        "            submit_button = gr.Button(\"Analyze Face\", variant=\"primary\")\n",
        "        with gr.Column(scale=2):\n",
        "            # Changed the number of lines to 6 as there is less text\n",
        "            output_text = gr.Textbox(label=\"Analysis Results\", lines=6)\n",
        "            output_landmarks_image = gr.Image(label=\"Input with Detected Landmarks\")\n",
        "\n",
        "    output_gallery = gr.Gallery(label=\"Image Gallery from Database\", height=\"auto\")\n",
        "\n",
        "    submit_button.click(\n",
        "        fn=recognize_face_with_all_features,\n",
        "        inputs=input_image,\n",
        "        outputs=[output_landmarks_image, output_gallery, output_text]\n",
        "    )\n",
        "\n",
        "if db_df is not None:\n",
        "    iface.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
